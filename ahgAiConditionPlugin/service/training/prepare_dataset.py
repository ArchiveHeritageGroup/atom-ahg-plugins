#!/usr/bin/env python3
"""
Prepare Dataset - Convert annotated images to YOLO format.

Takes a directory of images with corresponding annotation files and:
1. Creates YOLO-format label files (class_id, x_center, y_center, width, height)
2. Creates a data.yaml configuration file
3. Splits into train/val sets (80/20)

Expected input structure:
  dataset/
    images/
      img001.jpg
      img002.jpg
    annotations/
      img001.json    (or img001.xml for PASCAL VOC)
      img002.json

Output structure:
  dataset/
    data.yaml
    train/
      images/
      labels/
    val/
      images/
      labels/

Usage:
  python prepare_dataset.py --input /path/to/dataset --output /path/to/yolo_dataset
"""
import argparse
import json
import os
import random
import shutil
import sys

# Add parent directory to path for config access
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import config


DAMAGE_CLASS_MAP = {name: idx for idx, name in enumerate(config.DAMAGE_CLASSES)}


def parse_json_annotation(json_path: str, img_width: int, img_height: int) -> list:
    """
    Parse a JSON annotation file and return YOLO-format labels.

    Expected JSON format:
    {
        "damages": [
            {
                "type": "tear",
                "bbox": {"x1": 100, "y1": 50, "x2": 300, "y2": 200}
            }
        ]
    }

    Returns list of tuples: (class_id, x_center, y_center, width, height)
    All values normalized to 0-1 range.
    """
    with open(json_path, "r") as f:
        data = json.load(f)

    labels = []
    for damage in data.get("damages", []):
        damage_type = damage.get("type", "").lower().replace(" ", "_")
        if damage_type not in DAMAGE_CLASS_MAP:
            print(f"  Warning: Unknown damage type '{damage_type}', skipping")
            continue

        class_id = DAMAGE_CLASS_MAP[damage_type]
        bbox = damage.get("bbox", {})

        x1 = bbox.get("x1", 0)
        y1 = bbox.get("y1", 0)
        x2 = bbox.get("x2", 0)
        y2 = bbox.get("y2", 0)

        # Convert to YOLO format (normalized center x, center y, width, height)
        x_center = ((x1 + x2) / 2.0) / img_width
        y_center = ((y1 + y2) / 2.0) / img_height
        width = abs(x2 - x1) / img_width
        height = abs(y2 - y1) / img_height

        # Clamp to valid range
        x_center = max(0, min(1, x_center))
        y_center = max(0, min(1, y_center))
        width = max(0, min(1, width))
        height = max(0, min(1, height))

        labels.append((class_id, x_center, y_center, width, height))

    return labels


def create_data_yaml(output_dir: str) -> str:
    """Create the YOLO data.yaml configuration file."""
    yaml_content = f"""# AHG AI Condition Service - Damage Detection Dataset
# Auto-generated by prepare_dataset.py

path: {output_dir}
train: train/images
val: val/images

nc: {len(config.DAMAGE_CLASSES)}
names:
"""
    for i, name in enumerate(config.DAMAGE_CLASSES):
        yaml_content += f"  {i}: {name}\n"

    yaml_path = os.path.join(output_dir, "data.yaml")
    with open(yaml_path, "w") as f:
        f.write(yaml_content)

    return yaml_path


def prepare_dataset(input_dir: str, output_dir: str, val_split: float = 0.2):
    """
    Convert annotated dataset to YOLO format with train/val split.

    Args:
        input_dir: Directory with images/ and annotations/ subdirs.
        output_dir: Output directory for YOLO-format dataset.
        val_split: Fraction of images for validation (default 0.2).
    """
    images_dir = os.path.join(input_dir, "images")
    annotations_dir = os.path.join(input_dir, "annotations")

    if not os.path.isdir(images_dir):
        print(f"Error: images directory not found: {images_dir}")
        sys.exit(1)
    if not os.path.isdir(annotations_dir):
        print(f"Error: annotations directory not found: {annotations_dir}")
        sys.exit(1)

    # Create output directories
    for split in ("train", "val"):
        os.makedirs(os.path.join(output_dir, split, "images"), exist_ok=True)
        os.makedirs(os.path.join(output_dir, split, "labels"), exist_ok=True)

    # Find all image files
    image_extensions = {".jpg", ".jpeg", ".png", ".tiff", ".tif", ".bmp"}
    image_files = []
    for fname in os.listdir(images_dir):
        ext = os.path.splitext(fname)[1].lower()
        if ext in image_extensions:
            image_files.append(fname)

    if not image_files:
        print("Error: No image files found in", images_dir)
        sys.exit(1)

    print(f"Found {len(image_files)} images")

    # Shuffle and split
    random.seed(42)
    random.shuffle(image_files)
    val_count = max(1, int(len(image_files) * val_split))
    val_files = set(image_files[:val_count])
    train_files = set(image_files[val_count:])

    print(f"Split: {len(train_files)} train, {len(val_files)} val")

    processed = 0
    skipped = 0

    for fname in image_files:
        basename = os.path.splitext(fname)[0]
        ann_path = os.path.join(annotations_dir, basename + ".json")

        if not os.path.exists(ann_path):
            print(f"  Warning: No annotation for {fname}, skipping")
            skipped += 1
            continue

        # Get image dimensions
        try:
            from PIL import Image
            img = Image.open(os.path.join(images_dir, fname))
            img_width, img_height = img.size
        except Exception as e:
            print(f"  Warning: Cannot read {fname}: {e}, skipping")
            skipped += 1
            continue

        # Parse annotations
        labels = parse_json_annotation(ann_path, img_width, img_height)
        if not labels:
            print(f"  Warning: No valid labels for {fname}, skipping")
            skipped += 1
            continue

        # Determine split
        split = "val" if fname in val_files else "train"

        # Copy image
        src_img = os.path.join(images_dir, fname)
        dst_img = os.path.join(output_dir, split, "images", fname)
        shutil.copy2(src_img, dst_img)

        # Write YOLO label file
        label_fname = basename + ".txt"
        dst_label = os.path.join(output_dir, split, "labels", label_fname)
        with open(dst_label, "w") as f:
            for class_id, xc, yc, w, h in labels:
                f.write(f"{class_id} {xc:.6f} {yc:.6f} {w:.6f} {h:.6f}\n")

        processed += 1

    # Create data.yaml
    yaml_path = create_data_yaml(output_dir)

    print(f"\nDone:")
    print(f"  Processed: {processed}")
    print(f"  Skipped: {skipped}")
    print(f"  data.yaml: {yaml_path}")


def main():
    parser = argparse.ArgumentParser(
        description="Convert annotated images to YOLO format for damage detection training"
    )
    parser.add_argument(
        "--input", required=True,
        help="Input directory with images/ and annotations/ subdirs"
    )
    parser.add_argument(
        "--output", required=True,
        help="Output directory for YOLO-format dataset"
    )
    parser.add_argument(
        "--val-split", type=float, default=0.2,
        help="Validation split ratio (default: 0.2)"
    )
    args = parser.parse_args()

    prepare_dataset(args.input, args.output, args.val_split)


if __name__ == "__main__":
    main()
